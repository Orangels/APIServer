#include <unordered_map>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/imgproc/types_c.h>
//#include "caffePrototxtReader.h"
#include "cudaUtility.h"
#include "tensorNet.h"
#include "Common.h"
//#include "caffePlugin.h"
#include "FileFunction.h"
DimsCHW g_outputDim;
CTimer g_taskTimer, g_inferTimer;
std::unordered_map<int, std::unordered_map<std::string, TensorNet>> g_trtNetSet(8);

template<typename T>
void loadImage(int vHeight, int vWidth, T* vsrc, float* dst, int vBatchSize)
{
	/*
	PIXEL_MEANS: [103.52, 116.28, 123.675] #BGR order as well as cv2.imread
	PIXEL_STDS: [57.375, 57.12, 58.395]
	*/
	T* src = vsrc;
	unsigned int numPixel = vHeight * vWidth;
	float *p0 = dst, *p1 = dst + numPixel, *p2 = p1 + numPixel;
	while (numPixel--)
	{
		*p0 = (*src); p0++; src++;/*/ 255.f; src     */
		*p1 = (*src); p1++; src++;/*/ 255.f; src     */
		*p2 = (*src); p2++; src++;/*/ 255.f; src     */
	}
	unsigned int numElement = vHeight * vWidth * 3;
	for (int i = 1; i < vBatchSize; ++i)
	{
		memcpy(dst + numElement*i, dst, sizeof(T)*numElement);
	}
}

int _inference(int vBatchSize, float* vpImgData, void* vopPoint, const std::string& vFunctionName)
{
	int threadId = getThreadID(); 
	TensorNet& tensorNet = g_trtNetSet[threadId][vFunctionName];
	if ("keyPointInference" == vFunctionName && vBatchSize > 0)
		tensorNet.imagePreprocessor->cropResize(vBatchSize, (int*)vpImgData, tensorNet.cudaStream);
	else if ("ageGenderInference" == vFunctionName && vBatchSize > 0)
	{
		float* p68 = (float*)g_trtNetSet[threadId]["keyPointInference"].modelIObuffers.back();
		p68 += 62 * vBatchSize;
		tensorNet.affine(vBatchSize, p68);
	}
	else cudaMemcpyAsync(tensorNet.modelIObuffers[0], vpImgData, std::abs(vBatchSize)*tensorNet.modelInputBytes, cudaMemcpyHostToDevice, tensorNet.cudaStream);
	tensorNet.imageInference(std::abs(vBatchSize), vFunctionName);
	if ("keyPointInference" == vFunctionName)
		tensorNet.caculateDetail3Dkeypoints(std::abs(vBatchSize), vBatchSize>0 ? (int*)vpImgData : (int*)vopPoint);
	cudaStreamSynchronize(tensorNet.cudaStream);
	float* output = (float*)tensorNet.resultBufferHost;
	auto& d = tensorNet.m_dimsOut;
	size_t bites = d.c()*d.w()*d.h();
	if ("keyPointInference" == vFunctionName) bites += 219;
	bites *= std::abs(vBatchSize) * sizeof(float);
	memcpy(vopPoint, output, bites);
	// 	printf("cpp dst sum = %.2f\n", getSum((float*)output, std::abs(vBatchSize) * d.c()*d.w()*d.h()));
	return std::abs(vBatchSize);
}

void _outputSSD(float xMin, float yMin, float xMax, float yMax, float vConfidence, int vClassID)
{
	std::cout << vClassID << ", " << vConfidence << " : " << xMin << ", " << yMin << ", " << xMax << ", " << yMax << std::endl;
}
TensorNet* g_ptensor = NULL;
cudaStream_t g_cudaStream = NULL;
int  g_gpuindex = 0;
int g_batchSize = 1;
std::vector<int> get_dim_size(Dims dim)
{
	std::vector<int> size;
	for (int i = 0; i < dim.nbDims; ++i)
		size.emplace_back(dim.d[i]);
	return size;
}

int total_size(std::vector<int> dim)
{
	int size = 1 * sizeof(float);
	for (auto d : dim)
		size *= d;
	return size;
}
struct LayerInfo
{
	std::vector<int> dim;
	std::string name;
	int index;
	int size;
};
std::vector<LayerInfo> output_layer;
extern "C"
{
	void setMaxCameraNum(int vMaxThreadNum) { g_trtNetSet.reserve(vMaxThreadNum * 2); }
	void initialize(const char* vpModelPrefixFileName, char* vpFunctionName)
	{
		int maxBatchSize = g_batchSize; //it is valid only when creating tensorcache file and maxBatchSize>conterpart of model file.
		cudaSetDevice(g_gpuindex);

		if (g_trtNetSet.bucket_count() < 4) setMaxCameraNum(4);
		int threadId = getThreadID();
		std::cout << threadId << std::endl;
		std::string funName(vpFunctionName);
		TensorNet& tensorNet = g_trtNetSet[threadId][funName];
		std::string prefix(vpModelPrefixFileName);
		//if (isEndWith(prefix, "onnx")) maxBatchSize = 16;
		tensorNet.LoadNetwork(prefix, maxBatchSize, g_cudaStream);
		g_cudaStream = tensorNet.cudaStream;
		if (funName == "keyPointInference")
		{
			g_outputDim = tensorNet.allocateIOBuffer((62 + 73 * 3 + 4) * sizeof(float));//4 for box rect for development
			std::unordered_map<std::string, TensorNet>& threadModels = g_trtNetSet[threadId];
			if (threadModels.find("ssdInference") != threadModels.cend()) tensorNet.imagePreprocessor = threadModels["ssdInference"].imagePreprocessor;
			else tensorNet.imagePreprocessor = new CImagePreprocessor;
			tensorNet.imagePreprocessor->setSizeResizedImage(tensorNet.m_indims.w(), tensorNet.m_indims.h(), tensorNet.m_maxBatchSize, true);
			tensorNet.imagePreprocessor->setOutput((float*)tensorNet.modelIObuffers[0], true);
		}
		else
		{
			if (funName == "ageGenderInference")
			{
				std::unordered_map<std::string, TensorNet>& threadModels = g_trtNetSet[threadId];
				tensorNet.imagePreprocessor = threadModels["keyPointInference"].imagePreprocessor;
			}
			g_outputDim = tensorNet.allocateIOBuffer(0);
		}

		if (funName == "retinaFace")
		{
			auto& engine = tensorNet.m_pEngine;
			for (int b = 0; b < engine->getNbBindings(); ++b)
			{
				if (!engine->bindingIsInput(b))
				{
					LayerInfo l;
					l.name = engine->getBindingName(b);
					Dims dim_output = engine->getBindingDimensions(b);
					l.dim = get_dim_size(dim_output);
					l.size = total_size(l.dim);
					l.index = b;
					output_layer.emplace_back(l);
				}
			}

			std::cout << "RT init done!" << std::endl;
		}
	}

	int keyPointInference(int vBatchSize, float* vpImgData, void* vopPoint)
	{
		return _inference(vBatchSize, vpImgData, vopPoint, "keyPointInference");
	}
	int ageGenderInference(int vBatchSize, float* vpImgData, void* vopPoint)
	{
		return _inference(vBatchSize, vpImgData, vopPoint, "ageGenderInference");
	}

	int verifyFaceInference(int vBatchSize, float* vpImgData, void* vopPoint)
	{
		return _inference(vBatchSize, vpImgData, vopPoint, "verifyFaceInference");
	}

	int verifyFaceInference2(int vBatchSize, float* vpImgData, void* vopPoint)
	{
		g_cudaStream = NULL;
		return _inference(vBatchSize, vpImgData, vopPoint, "verifyFaceInference2");
	}

	int ssdInference(int vBatchSize, int vHeight, int vWidth, uchar* vpImgData,
		void* vopBoxScoreCls, int* vopNumDetections)
	{
		TensorNet& tensorNet = g_trtNetSet[getThreadID()]["ssdInference"];
		//int* pBox = (int*)vopBoxScore;
		float* pBoxScoreCls = (float*)vopBoxScoreCls;
		std::vector<cv::Mat> images(vBatchSize);
		int imgSize = vHeight * vWidth * 3;
		for (auto& image : images)
		{
			image = cv::Mat(vHeight, vWidth, CV_8UC3, vpImgData);
			vpImgData += imgSize;
		}
		tensorNet.imagePreprocessor->preprocess(images, tensorNet.cudaStream);
		g_inferTimer.start();
		tensorNet.imageInference(vBatchSize, "ssdInference");
		tensorNet.postSSD(vBatchSize, vHeight, vWidth);
		// 		if (0 != vopImage)
		// 			tensorNet.imagePreprocessor->getResizedImage((float*)tensorNet.modelIObuffers[0], (char*)vopImage, caffeReader.getDim()[3], caffeReader.getDim()[2], tensorNet.cudaStream);
		g_inferTimer.stop();
		g_ptensor = &tensorNet;

		auto& d = tensorNet.m_dimsOut;
		static int iter = 0; //iter++;
		int numAll = 0;
		for (int i = 0; i < vBatchSize; ++i)
		{
			float* output = (float*)tensorNet.resultBufferHost + i*tensorNet.modelOutputBytes / sizeof(float);
			int numDetection = *output, tnum = 0;
			for (int k = 0; k < numDetection; k++)
			{
				if (output[1] >= 0)
				{
					tnum++;
					memcpy(pBoxScoreCls, output + 3, 4 * sizeof(float));
					pBoxScoreCls[4] = output[2];
					pBoxScoreCls[5] = output[1];
//					if (1 == iter % 50) _outputSSD(output[3], output[4], output[5], output[6], output[2], output[1]);
					_outputSSD(output[3], output[4], output[5], output[6], output[2], output[1]);
					pBoxScoreCls += 6;
				}
				output += 7;
			}
			*vopNumDetections++ = tnum;
			numAll += tnum;
		}
		return  numAll;
	}

}

int g_iter = 1;
std::string g_modelPrefix;
#include <thread>
void testNameAgeGender(const std::string& vImageName)
{
	int vw = 112, vh = 112;
	initialize(g_modelPrefix.c_str(), "ageGenderInference");
	cv::Mat img = cv::imread(vImageName);
	img.convertTo(img, CV_32FC3);
	cv::resize(img, img, cv::Size(vw, vh));
	std::vector<float> data(vw * vh * 3 * g_batchSize);
	loadImage(vw, vh, (float*)img.data, data.data(), g_batchSize);

	std::vector<float> r(g_batchSize * g_outputDim.c()*g_outputDim.h()*g_outputDim.w(), 0);
	// 	std::vector<float> r(64*56*56);//64, 56, 56
	printf("%d, ageGenderInference input sumabs = %.2f, sum=%.2f, ", getThreadID(), getSum(data.data(), data.size()), getSum(data.data(), data.size(), false));
	for (int i = 0; i < g_iter; ++i)
	{
		ageGenderInference(-g_batchSize, data.data(), r.data());
	}
	printf("%d, ageGenderInference result sumabs = %.2f, sum=%.2f, ", g_batchSize, getSum(r.data(), r.size()), getSum(r.data(), r.size()) / g_batchSize);
}
void testVertify(const std::string& vImageName)
{
	int vw = 112, vh = 112;
	initialize(g_modelPrefix.c_str(), "verifyFaceInference");
	cv::Mat img = cv::imread(vImageName);
	img.convertTo(img, CV_32FC3);
	cv::resize(img, img, cv::Size(vw, vh));
	std::vector<float> data(vw * vh * 3 * g_batchSize);
	loadImage(vw, vh, (float*)img.data, data.data(), g_batchSize);

	std::vector<float> r(g_batchSize * g_outputDim.c()*g_outputDim.h()*g_outputDim.w(), 0);
	printf("%d, verifyFaceInference input sumabs = %.2f, sum=%.2f, ", getThreadID(), getSum(data.data(), data.size()), getSum(data.data(), data.size(), false));
	for (int i = 0; i < g_iter; ++i)
	{
		verifyFaceInference(-g_batchSize, data.data(), r.data());
	}
	printf("%d, verifyFaceInference result sumabs = %.2f, sum=%.2f, ", g_batchSize, getSum(r.data(), r.size()), getSum(r.data(), r.size()) / g_batchSize);
}

void test3DkeyPoints(const std::string& vImageName)
{
	int vw = 120, vh = 120;
	initialize(g_modelPrefix.c_str(), "keyPointInference");
	cv::Mat img = cv::imread(vImageName);
	img.convertTo(img, CV_32FC3);
	cv::resize(img, img, cv::Size(vw, vh));
	std::vector<float> data(vw * vh * 3 * g_batchSize);
	loadImage(vw, vh, (float*)img.data, data.data(), g_batchSize);
	std::vector<float> r(g_batchSize * (62 + 209));
	int face[] = { 0,0, 120, 120 };
	for (int k = 0; k < g_batchSize; ++k)
	{
		memcpy(r.data() + 4 * k, face, sizeof(face));
	}
	for (int i = 0; i < g_iter; ++i)
	{
		keyPointInference(-g_batchSize, data.data(), r.data());
	}
	printf("%d, ageGenderInference result sumabs = %.2f, sum=%.2f, ", getThreadID(), getSum(r.data(), r.size()), getSum(r.data(), r.size(), false));
}


void testSSD(const std::string& vImageName)
{
	std::vector<float> r;
//	float box_arr[800];
	float box_arr[120];
	float* box = box_arr;

	//initialize("/home/dbs/ssd4cls/ssd_PELEE-LITE-THIN-C3-BN-96HEAD-PROB02-FL_360x640_s2x_SCRATCH-PHFMeanVariance#", "ssdInference#"); //ssdPeleeFLMeanVariance   peleeMeanVariance ssdFLs2xMeanVariance ssdMbv2MeanVariance
	initialize(g_modelPrefix.c_str(), "ssdInference"); //ssdPeleeFLMeanVariance   peleeMeanVariance ssdFLs2xMeanVariance ssdMbv2MeanVariance
	cv::Mat faceImg = cv::imread(vImageName);

	g_inferTimer.start();

	int n = faceImg.cols*faceImg.rows*faceImg.channels();
	std::vector<uchar> imgs(n*g_batchSize);
	for (int i = 0; i < g_batchSize; ++i)
	{
		memcpy(imgs.data() + i*n, faceImg.data, n);
	}
	int numDetection = 0, nDets[64];
	for (int i = 0; i < g_iter; ++i)
		numDetection = ssdInference(g_batchSize, faceImg.rows, faceImg.cols, imgs.data(), box, nDets/*reFace.data*/);
	g_inferTimer.stop();
	std::cout << getThreadID() << " numDetection: " << numDetection << ": ";
	for (int i = 0; i < g_batchSize; ++i) std::cout << nDets[i] << ", "<< std::endl;
	for (int j = 0; j < numDetection; ++j) {
		std::cout << "********" << std::endl;
		std::cout << box[0]<< " : " << box[1] << " , " << box[2] << " , " << box[3] << " , " << box[4] << " , " << box[5] << " , " << std::endl;
		box += 6;
	}

}

int retinaFace(const std::string& vImageName);

int main()
{//just for test
	CConfiger* pConfiger = CConfiger::getOrCreateConfiger("../configer.txt");
	g_iter = pConfiger->readValue<int>("iter");
	g_modelPrefix = pConfiger->readValue("modelPrefix");
	int numThread = pConfiger->readValue<int>("numThread");
	g_batchSize = pConfiger->readValue<int>("batchSize");
	g_gpuindex = pConfiger->readValue<int>("gpuIndex");

	setMaxCameraNum(numThread);
	g_taskTimer.reset();
	g_inferTimer.reset();
	std::string imageFileName = pConfiger->readValue("imageFileName");
	std::string functionName = pConfiger->readValue("functionName");
	g_taskTimer.start();
	std::vector<std::thread> tds(numThread);
	CTimer  timer;

	for (int i = 0; i < numThread; ++i)
	{
		if (functionName == "retinaFace")
			tds[i] = std::thread(retinaFace,imageFileName);
		else if (functionName == "testSSD")
			tds[i] = std::thread(testSSD,imageFileName);
		else if (functionName == "testNameAgeGender")
			tds[i] = std::thread(testNameAgeGender,imageFileName);
		else if (functionName == "test3DkeyPoints")
			tds[i] = std::thread(test3DkeyPoints,imageFileName);
		else if (functionName == "testVertify")
			tds[i] = std::thread(testVertify,imageFileName);
// 		timer.sleep(500);
	}
	for (auto& t : tds)
		t.join();
	g_taskTimer.stop();
	std::cout << ", time=" << g_taskTimer.getTimeSpanSecond() / g_iter*1000.f << std::endl;
	std::cout << "inference time=" << g_inferTimer.getTimeSpanSecond() / g_iter*1000.f << std::endl;
	// 	printf("ageGenderInference result sumabs = %.2f, sum=%.2f, time=%.3fms, %.3fms\n", getSum(r.data(), r.size()), getSum(r.data(), r.size(), false), g_inferTimer.getTimeSpanSecond() / nt*1000.f, 1000.f * g_taskTimer.getTimeSpanSecond() / nt);
	// 	muntrace();
	// 	*/
	return 0;
}

using namespace nvinfer1;

static const int INPUT_H = 28;
static const int INPUT_W = 28;
static const int OUTPUT_SIZE = 10;

nvinfer1::ICudaEngine* g_engine;
int input_size;
int g_inputIndex;
bool g_fp16 = false;
int g_maxBatchSize = 1;

std::string  g_cacheFile = "retina.tensorcache";
std::string  g_onnxFileName = "../retina.onnx";
float m_nms_threshold = 0.4;
float data0[8] = { -248,-248,263,263,-120,-120,135,135 };
float data1[8] = { -56,-56,71,71,-24,-24,39,39 };
float data2[8] = { -8,-8,23,23,0,0,15,15 };


class Anchor {
public:
	bool operator<(const Anchor &t) const {
		return score < t.score;
	}

	bool operator>(const Anchor &t) const {
		return score > t.score;
	}

	float& operator[](int i) {
		assert(0 <= i && i <= 4);

		if (i == 0)
			return finalbox.x;
		if (i == 1)
			return finalbox.y;
		if (i == 2)
			return finalbox.width;
		if (i == 3)
			return finalbox.height;
	}

	float operator[](int i) const {
		assert(0 <= i && i <= 4);

		if (i == 0)
			return finalbox.x;
		if (i == 1)
			return finalbox.y;
		if (i == 2)
			return finalbox.width;
		if (i == 3)
			return finalbox.height;
	}

	cv::Rect_< float > anchor; // x1,y1,x2,y2
	float reg[4]; // offset reg
	cv::Point center; // anchor feat center
	float score; // cls score
	std::vector<cv::Point2f> pts; // pred pts

	cv::Rect_< float > finalbox; // final box res
};

void nms_cpu(std::vector<Anchor>& boxes, float threshold, std::vector<Anchor>& filterOutBoxes) {
	filterOutBoxes.clear();
	if (boxes.size() == 0)
		return;
	std::vector<size_t> idx(boxes.size());

	for (unsigned i = 0; i < idx.size(); i++)
	{
		idx[i] = i;
	}

	//descending sort
	sort(boxes.begin(), boxes.end(), std::greater<Anchor>());

	while (idx.size() > 0)
	{
		int good_idx = idx[0];
		filterOutBoxes.push_back(boxes[good_idx]);

		std::vector<size_t> tmp = idx;
		idx.clear();
		for (unsigned i = 1; i < tmp.size(); i++)
		{
			int tmp_i = tmp[i];
			float inter_x1 = std::max(boxes[good_idx][0], boxes[tmp_i][0]);
			float inter_y1 = std::max(boxes[good_idx][1], boxes[tmp_i][1]);
			float inter_x2 = std::min(boxes[good_idx][2], boxes[tmp_i][2]);
			float inter_y2 = std::min(boxes[good_idx][3], boxes[tmp_i][3]);

			float w = std::max((inter_x2 - inter_x1 + 1), 0.0F);
			float h = std::max((inter_y2 - inter_y1 + 1), 0.0F);

			float inter_area = w * h;
			float area_1 = (boxes[good_idx][2] - boxes[good_idx][0] + 1) * (boxes[good_idx][3] - boxes[good_idx][1] + 1);
			float area_2 = (boxes[tmp_i][2] - boxes[tmp_i][0] + 1) * (boxes[tmp_i][3] - boxes[tmp_i][1] + 1);
			float o = inter_area / (area_1 + area_2 - inter_area);
			if (o <= threshold)
				idx.push_back(tmp_i);
		}
	}
}

class CRect2f {
public:
	CRect2f(float x1, float y1, float x2, float y2) {
		val[0] = x1;
		val[1] = y1;
		val[2] = x2;
		val[3] = y2;
	}

	float& operator[](int i) {
		return val[i];
	}

	float operator[](int i) const {
		return val[i];
	}

	float val[4];

	void print() {
		printf("rect %f %f %f %f\n", val[0], val[1], val[2], val[3]);
	}
};

class AnchorGenerator {
public:
	void Init(int stride, int num, float* data)
	{
		anchor_stride = stride; // anchor tile stride
		preset_anchors.push_back(CRect2f(data[0], data[1], data[2], data[3]));
		preset_anchors.push_back(CRect2f(data[4], data[5], data[6], data[7]));
		anchor_num = num; // anchor type num
	}
	// filter anchors and return valid anchors
	int FilterAnchor(float* cls, float* reg, float* pts, int w, int h, int c, std::vector<Anchor>& result)
	{
		int pts_length = 0;

		pts_length = c / anchor_num / 2;

		for (int i = 0; i < h; ++i) {
			for (int j = 0; j < w; ++j) {
				int id = i * w + j;
				for (int a = 0; a < anchor_num; ++a)
				{
					float score = cls[(anchor_num + a)*w*h + id];
					if (score >= m_cls_threshold) {
						CRect2f box(j * anchor_stride + preset_anchors[a][0],
							i * anchor_stride + preset_anchors[a][1],
							j * anchor_stride + preset_anchors[a][2],
							i * anchor_stride + preset_anchors[a][3]);
						//printf("%f %f %f %f\n", box[0], box[1], box[2], box[3]);
						CRect2f delta(reg[(a * 4 + 0)*w*h + id],
							reg[(a * 4 + 1)*w*h + id],
							reg[(a * 4 + 2)*w*h + id],
							reg[(a * 4 + 3)*w*h + id]);

						Anchor res;
						res.anchor = cv::Rect_< float >(box[0], box[1], box[2], box[3]);
						bbox_pred(box, delta, res.finalbox);
						//printf("bbox pred\n");
						res.score = score;
						res.center = cv::Point(j, i);

						//printf("center %d %d\n", j, i);

						if (1) {
							std::vector<cv::Point2f> pts_delta(pts_length);
							for (int p = 0; p < pts_length; ++p) {
								pts_delta[p].x = pts[(a*pts_length * 2 + p * 2)*w*h + id];
								pts_delta[p].y = pts[(a*pts_length * 2 + p * 2 + 1)*w*h + id];
							}
							//printf("ready landmark_pred\n");
							landmark_pred(box, pts_delta, res.pts);
							//printf("landmark_pred\n");
						}
						result.push_back(res);
					}
				}
			}
		}
		return 0;
	}

private:
	void bbox_pred(const CRect2f& anchor, const CRect2f& delta, cv::Rect_< float >& box)
	{
		float w = anchor[2] - anchor[0] + 1;
		float h = anchor[3] - anchor[1] + 1;
		float x_ctr = anchor[0] + 0.5 * (w - 1);
		float y_ctr = anchor[1] + 0.5 * (h - 1);

		float dx = delta[0];
		float dy = delta[1];
		float dw = delta[2];
		float dh = delta[3];

		float pred_ctr_x = dx * w + x_ctr;
		float pred_ctr_y = dy * h + y_ctr;
		float pred_w = std::exp(dw) * w;
		float pred_h = std::exp(dh) * h;

		box = cv::Rect_< float >(pred_ctr_x - 0.5 * (pred_w - 1.0),
			pred_ctr_y - 0.5 * (pred_h - 1.0),
			pred_ctr_x + 0.5 * (pred_w - 1.0),
			pred_ctr_y + 0.5 * (pred_h - 1.0));
	}

	void landmark_pred(const CRect2f anchor, const std::vector<cv::Point2f>& delta, std::vector<cv::Point2f>& pts)
	{
		float w = anchor[2] - anchor[0] + 1;
		float h = anchor[3] - anchor[1] + 1;
		float x_ctr = anchor[0] + 0.5 * (w - 1);
		float y_ctr = anchor[1] + 0.5 * (h - 1);

		pts.resize(delta.size());
		for (int i = 0; i < delta.size(); ++i) {
			pts[i].x = delta[i].x*w + x_ctr;
			pts[i].y = delta[i].y*h + y_ctr;
		}
	}

	int anchor_stride; // anchor tile stride
	std::vector<CRect2f> preset_anchors;
	int anchor_num; // anchor type num
	float m_cls_threshold = 0.4;
};



float* cls[3];
float* reg[3];
float* pts[3];
AnchorGenerator ac[3];

Logger g_logger;

CTimer g_timer;
#define wh 640
void doInference(cv::Mat img, std::vector<Anchor>& vofaces)
{
	cv::Mat image = img.clone();
	cv::Mat image_temp;
	cv::cvtColor(image, image, CV_BGR2RGB);
	cv::Mat image_resize(cv::Size(wh, wh), CV_8UC3);
	float resize_scale = 1;
	if (image.cols >= image.rows&&image.cols > wh)
	{
		resize_scale = float(wh) / image.cols;
		cv::resize(image, image_temp, cv::Size(0, 0), resize_scale, resize_scale);
	}
	else if (image.cols < image.rows&&image.rows>wh)
	{
		resize_scale = float(wh) / image.rows;
		cv::resize(image, image_temp, cv::Size(0, 0), resize_scale, resize_scale);
	}
	else
	{
		image_temp = image.clone();
	}
	cv::Mat imageROI0(image_resize(cv::Rect(0, 0, image_temp.cols, image_temp.rows)));
	image_temp.copyTo(imageROI0);
	int total_size = image_resize.rows*image_resize.cols*image_resize.channels();
	std::vector<float> input;
	input.resize(total_size);
	for (int k = 0; k < 3; k++)
		for (int i = 0; i < image_resize.rows; i++)
			for (int j = 0; j < image_resize.cols; j++)
			{
				input[i * image_resize.cols + j + k * image_resize.cols * image_resize.rows] =
					(float)image_resize.data[(i * image_resize.cols + j) * 3 + k];
			}

	std::cout << "input: " << getSum(input.data(), input.size()) << std::endl;
	TensorNet& tensorNet = g_trtNetSet[getThreadID()]["retinaFace"];
	auto& buffers = tensorNet.modelIObuffers;
	auto stream = tensorNet.cudaStream;
	std::vector<std::vector<float>> output;
	output.resize(output_layer.size());
	for (int i = 0; i < output_layer.size(); ++i)
		output[i].resize(output_layer[i].size / sizeof(float));
	input_size = input.size()*sizeof(float);
	cudaMemcpyAsync(buffers[g_inputIndex], input.data(), input_size, cudaMemcpyHostToDevice, stream);
	cudaStreamSynchronize(stream);
//	CCaffePlugin::_printGPUdata((float*)buffers[0], input_size / 4, stream, "gpu input");
	std::cout << "inferencing..." << std::endl;
	g_timer.start();
	for (int i = 0; i < g_iter; ++i)
	{
		tensorNet.imageInference(1, "retinaFace");
		cudaStreamSynchronize(stream);
	}
	g_timer.stop();

	for (int i = 0; i < output_layer.size() ; ++i)
		cudaMemcpyAsync(output[i].data(), buffers[output_layer[i].index], output_layer[i].size, cudaMemcpyDeviceToHost, stream);
// 	for (int i = 0; i < output_layer.size(); ++i)
// 		CCaffePlugin::_printGPUdata((float*)buffers[output_layer[i].index], output_layer[i].size / 4, stream, std::to_string(output_layer[i].index) + " gpu");
	cudaStreamSynchronize(stream);


	for (int i = 0; i < 3; ++i)
	{
		reg[i] = output[i * 3 + 0].data();
		pts[i] = output[i * 3 + 1].data();
		cls[i] = output[i * 3 + 2].data();
	}
	std::vector<Anchor> proposals;
	for (int i = 0; i < 3; i++)
	{
		ac[i].FilterAnchor(cls[i], reg[i], pts[i], output_layer[i * 3 + 1].dim[2],
			output_layer[i * 3 + 1].dim[1], output_layer[i * 3 + 1].dim[0], proposals);
	}
	vofaces.clear();
	nms_cpu(proposals, m_nms_threshold, vofaces);
	std::sort(vofaces.begin(), vofaces.end(), [&](Anchor a, Anchor b)
	{
		return a.finalbox.area() > b.finalbox.area();
	});
	for (auto &face : vofaces)
	{
		face.finalbox.width /= resize_scale;
		face.finalbox.x /= resize_scale;
		face.finalbox.height /= resize_scale;
		face.finalbox.y /= resize_scale;
		for (int i = 0; i < 5; ++i)
		{
			face.pts[i].x /= resize_scale;
			face.pts[i].y /= resize_scale;
		}
	}

}


int retinaFace(const std::string& vImageName)
{
	float data0[8] = { -248,-248,263,263,-120,-120,135,135 };
	float data1[8] = { -56,-56,71,71,-24,-24,39,39 };
	float data2[8] = { -8,-8,23,23,0,0,15,15 };
	ac[0].Init(32, 2, data0);
	ac[1].Init(16, 2, data1);
	ac[2].Init(8, 2, data2);

	initialize(g_modelPrefix.c_str(), "retinaFace");
	cv::Mat image = cv::imread(vImageName);
	std::vector<Anchor> faces;

	for (int i = 0; i < 1; i++)
	{
		doInference(image, faces);
	}
	std::cout << faces.size() << "retina inference time: " << g_timer.getTimeSpanSecond() / g_iter << std::endl;
	for (int i = 0; i < faces.size(); i++)
	{
		cv::rectangle(image, cv::Point((int)faces[i].finalbox.x, (int)faces[i].finalbox.y), cv::Point((int)faces[i].finalbox.width, (int)faces[i].finalbox.height), cv::Scalar(0, 255, 255), 2, 8, 0);
		for (int j = 0; j < faces[i].pts.size(); ++j) {
			cv::circle(image, cv::Point((int)faces[i].pts[j].x, (int)faces[i].pts[j].y), 1, cv::Scalar(225, 0, 225), 2, 8);
		}
	}

	cv::imwrite("result.jpg", image);
	// 	cv::imshow("img", image);
	// 	cv::waitKey(0);
}
